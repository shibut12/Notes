# Dynamic Programming

Is a mathematical optimization and a computer programming model. It was developed by __Richard Bellman__ in the 1950s.

In a nutshell, it is _simplifying a complicated problem by breaking it down to sequence of decision steps over time_. This is done by defining a sequence of __value functions_ v1, v2, v3...vn_, with an argument__y__ representing the __state__ of the system at times __i__ from __1 to n__. The definition of __Vn(y)__ is the value obtained in state __y__ at the last time __n__. The values __Vi__ at earlier times __i=n-1, n-2, n-3, ...2, 1__ can be found by _working backwards_, using a _recursive relation ship_ called the [Bellman Equation](https://en.wikipedia.org/wiki/Bellman_equation). For _i=2, ...., n, Vi-1_ at any state _y_ is calculated from _Vi_ by maximizing  a simple function (usually the sum) of the gain from a decision at time _i-1_ and the function _Vi_ at the new state of the system if this decision is made. Since _Vi_ has already been calculated for the needed states, the above operation yields _Vi-1_ for those states. Finally _V1_ at the initial state of the system is the optimal solution. The optimal values of the decision variables can be covered, on by one by tracking back the calculations already performed.